{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba081119",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "significant-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-metadata",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ec64200",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_RATIO = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ce48042",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat',sep='::',header=None,names=[\"MovieID\", \"Title\", \"Genres\"],engine='python')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat',sep='::',header=None,names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"],engine='python')\n",
    "users = pd.read_csv('ml-1m/users.dat',sep='::',header=None,names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"],engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "371850af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4df1ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  Occupation Zip-code\n",
       "0       1      F    1          10    48067\n",
       "1       2      M   56          16    70072\n",
       "2       3      M   25          15    55117\n",
       "3       4      M   45           7    02460\n",
       "4       5      M   25          20    55455"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a785e1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbefd7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3883, 3), (1000209, 4), (6040, 5))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape, ratings.shape, users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1259e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MovieID\n",
       "UserID         \n",
       "947          20\n",
       "4068         20\n",
       "2530         20\n",
       "341          20\n",
       "5258         20\n",
       "...         ...\n",
       "1181       1521\n",
       "1941       1595\n",
       "4277       1743\n",
       "1680       1850\n",
       "4169       2314\n",
       "\n",
       "[6040 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.groupby('UserID').count()[[\"MovieID\"]].sort_values(by=\"MovieID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fc8ece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MovieID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3382</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>3428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3706 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID\n",
       "MovieID        \n",
       "402           1\n",
       "2214          1\n",
       "3382          1\n",
       "2217          1\n",
       "2218          1\n",
       "...         ...\n",
       "480        2672\n",
       "1210       2883\n",
       "1196       2990\n",
       "260        2991\n",
       "2858       3428\n",
       "\n",
       "[3706 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.groupby('MovieID').count()[[\"UserID\"]].sort_values(by=\"UserID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1dd657da",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_CNT = 6040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f204b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sitting-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = train_test_split(ratings, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26849437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sparse_matrix(dataset):\n",
    "    items_max_id = dataset.MovieID.max()\n",
    "\n",
    "    items = np.zeros(shape = (items_max_id, USERS_CNT), dtype = np.float32)\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        items[int(row['MovieID'] - 1), int(row['UserID'] - 1)] = row['Rating']\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "imperial-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_matrix = generate_sparse_matrix(train_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "clear-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3952, 6040)\n"
     ]
    }
   ],
   "source": [
    "test_sparse_matrix = generate_sparse_matrix(test_ratings)\n",
    "print(test_sparse_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "suitable-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sparse Matrix:  (3952, 6040)\n",
      "Test Sparse Matrix:  (3952, 6040)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Sparse Matrix: \", train_sparse_matrix.shape)\n",
    "print(\"Test Sparse Matrix: \", test_sparse_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60de34de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900188, 4), (100021, 4))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.shape, test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b37eda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RatingsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ratings):\n",
    "        self.ratings = ratings.copy()\n",
    "        self.known_indices = self.get_known_indices()\n",
    "        self.normalize()\n",
    "        self.subtract_mean()\n",
    "        \n",
    "        self.masked_ratings, self.masked_indices = self.mask_ratings()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        result = {\n",
    "            'inp': torch.from_numpy(np.array(self.masked_ratings[index])).float(), \n",
    "            'out': torch.from_numpy(np.array(self.ratings[index])).float(),\n",
    "            'known_indices': self.known_indices[index],\n",
    "            'masked_indices': self.masked_indices[index]\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def get_known_indices(self):\n",
    "        known_indices = np.zeros(shape = self.ratings.shape)\n",
    "\n",
    "        for index, rating in enumerate(self.ratings):\n",
    "            known = np.where(rating > 0)[0].tolist()\n",
    "            known_indices[index][known] = 1\n",
    "            \n",
    "        return known_indices\n",
    "        \n",
    "    def mask_ratings(self):\n",
    "    \n",
    "        masked_ratings = self.ratings.copy()\n",
    "        masked_indices = np.zeros(shape = self.ratings.shape)\n",
    "                \n",
    "        for index, rating in enumerate(masked_ratings):\n",
    "            \n",
    "            known = np.where(self.known_indices[index] == 1)[0].tolist()\n",
    "            known_cnt = len(known)\n",
    "            masked_features_cnt = int(MASK_RATIO * known_cnt)\n",
    "            masked = random.sample(known, masked_features_cnt)\n",
    "            rating[masked] = 0\n",
    "                        \n",
    "            masked_indices[index][masked] = 1\n",
    "            \n",
    "            \n",
    "        return masked_ratings, masked_indices\n",
    "    \n",
    "    def normalize(self):\n",
    "        \n",
    "        for index, rating in enumerate(self.ratings):\n",
    "            known = np.where(self.known_indices[index] == 1)[0]\n",
    "            \n",
    "            if len(known) > 0:\n",
    "                rating[known] -= 3\n",
    "                rating[known] /= 2\n",
    "    \n",
    "    def subtract_mean(self):\n",
    "        \n",
    "        for index, rating in enumerate(self.ratings):\n",
    "            \n",
    "            known = np.where(self.known_indices[index] == 1)[0]\n",
    "            \n",
    "            if len(known) > 0:\n",
    "                mean = rating[known].mean()\n",
    "                rating[known] -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49bdd0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([0.4215, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]) Input Length:  6040\n",
      "Output:  tensor([ 0.4215,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.5785]) Output Length:  6040\n",
      "Input:  tensor([0., 0., 0.,  ..., 0., 0., 0.]) Input Length:  6040\n",
      "Output:  tensor([0., 0., 0.,  ..., 0., 0., 0.]) Output Length:  6040\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RatingsDataset(train_sparse_matrix)\n",
    "print(\"Input: \", train_dataset[0]['inp'], \"Input Length: \", len(train_dataset[0]['inp']))\n",
    "print(\"Output: \", train_dataset[0]['out'], \"Output Length: \", len(train_dataset[5]['out']))\n",
    "\n",
    "test_dataset = RatingsDataset(test_sparse_matrix)\n",
    "print(\"Input: \", test_dataset[0]['inp'], \"Input Length: \", len(test_dataset[5]['inp']))\n",
    "print(\"Output: \", test_dataset[0]['out'], \"Output Length: \", len(test_dataset[5]['out']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2e179e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inp': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'out': tensor([0., 0., 0.,  ..., 0., 0., 0.]), 'known_indices': array([0., 0., 0., ..., 0., 0., 0.]), 'masked_indices': array([0., 0., 0., ..., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-style",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25373092",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1\n",
    "BETA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "first-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising_Model(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=6040, out_features=770, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=770, out_features=6040, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "inputSize = 6040\n",
    "class Denoising_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Denoising_Model,self).__init__()\n",
    "        self.encoder=nn.Sequential(\n",
    "                      nn.Linear(inputSize, 770),  # There are 6040 users in movieLens-1M\n",
    "                      nn.Tanh()\n",
    "                      )\n",
    "\n",
    "        self.decoder=nn.Sequential(\n",
    "                      nn.Linear(770, inputSize),\n",
    "                      nn.Tanh()\n",
    "                      )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "network = Denoising_Model()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4d39a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denosingLoss(output, target, known, masked):\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for index, out in enumerate(output):\n",
    "            out = output[index]\n",
    "\n",
    "            known_indices = np.where(known[index] == 1)[0]\n",
    "            masked_indices = np.where(masked[index] == 1)[0]\n",
    "            known_masked_diff = list(set(known_indices) - set(masked_indices))        \n",
    "\n",
    "            masked_output = output[index][masked_indices]\n",
    "            masked_target = target[index][masked_indices]\n",
    "            known_masked_diff_output = output[index][known_masked_diff]\n",
    "            known_masked_diff_target = target[index][known_masked_diff]\n",
    "\n",
    "            if len(masked_output) > 0 and len(known_masked_diff_output) > 0:\n",
    "                loss += ALPHA * torch.sum(torch.square(torch.sub(masked_output, masked_target))) \\\n",
    "                        + BETA * torch.sum(torch.square(torch.sub(known_masked_diff_output, known_masked_diff_target)))\n",
    "\n",
    "        return loss / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "frozen-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3952\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "230b9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "familiar-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, masked_ratings, target, optimizer, criterion, known, masked):   \n",
    "#     masked_ratings,target=masked_ratings.to(device),target.to(device)\n",
    "    \n",
    "    # Forward Pass\n",
    "    output = model(masked_ratings)\n",
    "    loss = denosingLoss(output, target, known, masked)\n",
    "        \n",
    "    #Backward Pass---------------------\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "   # scheduler.step()\n",
    "\n",
    "    return loss, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77d47c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 0.8250147104263306\n",
      "Epoch 2 Loss : 0.6871721148490906\n",
      "Epoch 3 Loss : 0.64995938539505\n",
      "Epoch 4 Loss : 0.6287932395935059\n",
      "Epoch 5 Loss : 0.6133947968482971\n",
      "Epoch 6 Loss : 0.5997771620750427\n",
      "Epoch 7 Loss : 0.590453028678894\n",
      "Epoch 8 Loss : 0.5852393507957458\n",
      "Epoch 9 Loss : 0.5781346559524536\n",
      "Epoch 10 Loss : 0.575422465801239\n",
      "Epoch 11 Loss : 0.5703805088996887\n",
      "Epoch 12 Loss : 0.5687387585639954\n",
      "Epoch 13 Loss : 0.5683459043502808\n",
      "Epoch 14 Loss : 0.5641975402832031\n",
      "Epoch 15 Loss : 0.5616698265075684\n",
      "Epoch 16 Loss : 0.5644431710243225\n",
      "Epoch 17 Loss : 0.5604658722877502\n",
      "Epoch 18 Loss : 0.5583814978599548\n",
      "Epoch 19 Loss : 0.5593565702438354\n",
      "Epoch 20 Loss : 0.5592248439788818\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# if torch.cuda.is_available() == True:\n",
    "#     device=\"cuda:0\"\n",
    "# else:\n",
    "device =\"cpu\"\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "model = Denoising_Model().to(device)\n",
    "init_weights(model)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer=Adam(model.parameters(),lr=0.07,weight_decay=0.05)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.07, weight_decay = 0.05)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.3)\n",
    "\n",
    "epoch_loss = 0\n",
    "epoch_loss = []\n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "    acc_epoch_loss = 0\n",
    "    \n",
    "    for bidx, batch in enumerate(train_loader):\n",
    "        \n",
    "        x_train = batch['inp']\n",
    "        y_train = batch['out']\n",
    "        known = batch['known_indices']\n",
    "        masked = batch['masked_indices']\n",
    "        \n",
    "        loss, predictions = train(model, x_train, y_train, optimizer, criterion, known, masked)\n",
    "        acc_epoch_loss += loss\n",
    "    \n",
    "    epoch_loss.append(acc_epoch_loss / len(train_dataset))        \n",
    "    print('Epoch {} Loss : {}'.format((epoch+1), epoch_loss[epoch] ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "sized-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  1  Current RMSE:  1.3175424920619052\n",
      "Batch:  2  Current RMSE:  1.293462296494265\n",
      "Batch:  3  Current RMSE:  1.2695759006850378\n",
      "Batch:  4  Current RMSE:  1.270294135393176\n",
      "Batch:  5  Current RMSE:  1.2394079661518267\n",
      "Batch:  6  Current RMSE:  1.262890731821855\n",
      "Batch:  7  Current RMSE:  1.2105669159932493\n",
      "Batch:  8  Current RMSE:  1.238499769793109\n",
      "Batch:  9  Current RMSE:  1.2548243663895429\n",
      "Batch:  10  Current RMSE:  1.2481887364713014\n",
      "Batch:  11  Current RMSE:  1.203433725388999\n",
      "Batch:  12  Current RMSE:  1.2201457925950432\n",
      "Batch:  13  Current RMSE:  1.2640217147496189\n",
      "Batch:  14  Current RMSE:  1.2921139569622433\n",
      "Batch:  15  Current RMSE:  1.2577125001165368\n",
      "Batch:  16  Current RMSE:  1.249674546647189\n",
      "Batch:  17  Current RMSE:  1.2579707496192092\n",
      "Batch:  18  Current RMSE:  1.2297786162098618\n",
      "Batch:  19  Current RMSE:  1.2532898140573923\n",
      "Batch:  20  Current RMSE:  1.2935682189556168\n",
      "Batch:  21  Current RMSE:  1.2274871005106804\n",
      "Batch:  22  Current RMSE:  1.2671263518788294\n",
      "Batch:  23  Current RMSE:  1.2561640829766398\n",
      "Batch:  24  Current RMSE:  1.2403920064601017\n",
      "Batch:  25  Current RMSE:  1.2744255863375142\n",
      "Batch:  26  Current RMSE:  1.2322483562599547\n",
      "Batch:  27  Current RMSE:  1.2733910015088965\n",
      "Batch:  28  Current RMSE:  1.2748936681416576\n",
      "Batch:  29  Current RMSE:  1.2701018396365142\n",
      "Batch:  30  Current RMSE:  1.3092612620829638\n",
      "Batch:  31  Current RMSE:  1.2987535322027746\n",
      "Batch:  32  Current RMSE:  1.2896588306189893\n",
      "Batch:  33  Current RMSE:  1.2009497689383646\n",
      "Batch:  34  Current RMSE:  1.2047922451412014\n",
      "Batch:  35  Current RMSE:  1.276141098096079\n",
      "Batch:  36  Current RMSE:  1.2558185763755958\n",
      "Batch:  37  Current RMSE:  1.2723119771949225\n",
      "Batch:  38  Current RMSE:  1.2358997711169895\n",
      "Batch:  39  Current RMSE:  1.2423171283320729\n",
      "Batch:  40  Current RMSE:  1.281929935961847\n",
      "Batch:  41  Current RMSE:  1.2335832478237647\n",
      "Batch:  42  Current RMSE:  1.24381496397498\n",
      "Batch:  43  Current RMSE:  1.266384332959328\n",
      "Batch:  44  Current RMSE:  1.2556348695347117\n",
      "Batch:  45  Current RMSE:  1.265875407093959\n",
      "Batch:  46  Current RMSE:  1.2921942602259608\n",
      "Batch:  47  Current RMSE:  1.228996545194076\n",
      "Batch:  48  Current RMSE:  1.199037906418844\n",
      "Batch:  49  Current RMSE:  1.2751297297119017\n",
      "Batch:  50  Current RMSE:  1.3824239153488915\n",
      "Batch:  51  Current RMSE:  1.2637858298958817\n",
      "Batch:  52  Current RMSE:  1.2010915206892316\n",
      "Batch:  53  Current RMSE:  1.2144267369927944\n",
      "Batch:  54  Current RMSE:  1.2547334033314332\n",
      "Batch:  55  Current RMSE:  1.2072642161129044\n",
      "Batch:  56  Current RMSE:  1.2115239861597278\n",
      "Batch:  57  Current RMSE:  1.2077987455796977\n",
      "Batch:  58  Current RMSE:  1.2202947345633457\n",
      "Batch:  59  Current RMSE:  1.2170437209138698\n",
      "Batch:  60  Current RMSE:  1.210787415695181\n",
      "Batch:  61  Current RMSE:  1.2009069697528796\n",
      "Batch:  62  Current RMSE:  1.2869040880774434\n",
      "Batch:  63  Current RMSE:  1.2118789876156835\n",
      "Batch:  64  Current RMSE:  1.2242916975991467\n",
      "Batch:  65  Current RMSE:  1.2471060827745\n",
      "Batch:  66  Current RMSE:  1.2832479068824616\n",
      "Batch:  67  Current RMSE:  1.2384253829656773\n",
      "Batch:  68  Current RMSE:  1.2076671332051672\n",
      "Batch:  69  Current RMSE:  1.1903494823096519\n",
      "Batch:  70  Current RMSE:  1.2721220492646022\n",
      "Batch:  71  Current RMSE:  1.2502649404644106\n",
      "Batch:  72  Current RMSE:  1.2099546112785062\n",
      "Batch:  73  Current RMSE:  1.1957064152243253\n",
      "Batch:  74  Current RMSE:  1.2180333908249033\n",
      "Batch:  75  Current RMSE:  1.2113513081376852\n",
      "Batch:  76  Current RMSE:  1.2689484079613598\n",
      "Batch:  77  Current RMSE:  1.3159147276068899\n",
      "Batch:  78  Current RMSE:  1.2519329434223565\n",
      "Batch:  79  Current RMSE:  1.2089515564382516\n",
      "Batch:  80  Current RMSE:  1.233928062749333\n",
      "Batch:  81  Current RMSE:  1.222011850473715\n",
      "Batch:  82  Current RMSE:  1.187698188662352\n",
      "Batch:  83  Current RMSE:  1.2295389451455456\n",
      "Batch:  84  Current RMSE:  1.2211118476525344\n",
      "Batch:  85  Current RMSE:  1.2573936680446707\n",
      "Batch:  86  Current RMSE:  1.2664567527315242\n",
      "Batch:  87  Current RMSE:  1.280422731215548\n",
      "Batch:  88  Current RMSE:  1.2276711607260982\n",
      "Batch:  89  Current RMSE:  1.235021869406092\n",
      "Batch:  90  Current RMSE:  1.256074875750017\n",
      "Batch:  91  Current RMSE:  1.2890217194847986\n",
      "Batch:  92  Current RMSE:  1.3075224848804983\n",
      "Batch:  93  Current RMSE:  1.2000119396341493\n",
      "Batch:  94  Current RMSE:  1.242418188711244\n",
      "Batch:  95  Current RMSE:  1.242724540625113\n",
      "Batch:  96  Current RMSE:  1.1988177558311564\n",
      "Batch:  97  Current RMSE:  1.192187821056551\n",
      "Batch:  98  Current RMSE:  1.222423540486158\n",
      "Batch:  99  Current RMSE:  1.261518856821638\n",
      "Batch:  100  Current RMSE:  1.3445370653432394\n",
      "Batch:  101  Current RMSE:  1.314410304880232\n",
      "Batch:  102  Current RMSE:  1.3255127788161827\n",
      "Batch:  103  Current RMSE:  1.2736566100177626\n",
      "Batch:  104  Current RMSE:  1.2793449108205335\n",
      "Batch:  105  Current RMSE:  1.2811575566637023\n",
      "Batch:  106  Current RMSE:  1.3026251362771488\n",
      "Batch:  107  Current RMSE:  1.2698450291781926\n",
      "Batch:  108  Current RMSE:  1.2965629176207538\n",
      "Batch:  109  Current RMSE:  1.2775925805168151\n",
      "Batch:  110  Current RMSE:  1.2225668249370192\n",
      "Batch:  111  Current RMSE:  1.2281725384775668\n",
      "Batch:  112  Current RMSE:  1.2745981437448335\n",
      "Batch:  113  Current RMSE:  1.2576366534707129\n",
      "Batch:  114  Current RMSE:  1.2443938286394993\n",
      "Batch:  115  Current RMSE:  1.3878325579199946\n",
      "Batch:  116  Current RMSE:  1.2755095569275718\n",
      "Batch:  117  Current RMSE:  1.2645947127072152\n",
      "Batch:  118  Current RMSE:  1.2639182139229743\n",
      "Batch:  119  Current RMSE:  1.2023811706827936\n",
      "Batch:  120  Current RMSE:  1.2150839887600886\n",
      "Batch:  121  Current RMSE:  1.2184154545841486\n",
      "Batch:  122  Current RMSE:  1.2345075115133155\n",
      "Batch:  123  Current RMSE:  1.2319764128428379\n",
      "Batch:  124  Current RMSE:  1.2781809084454618\n",
      "Batch:  125  Current RMSE:  1.2422860275939909\n",
      "Batch:  126  Current RMSE:  1.196602445212533\n",
      "Batch:  127  Current RMSE:  1.2463951827302455\n",
      "Batch:  128  Current RMSE:  1.2399120436228437\n",
      "Batch:  129  Current RMSE:  1.23818677594983\n",
      "Batch:  130  Current RMSE:  1.2283895206968503\n",
      "Batch:  131  Current RMSE:  1.239602329891055\n",
      "Batch:  132  Current RMSE:  1.3006294558407783\n",
      "Batch:  133  Current RMSE:  1.2880092513446217\n",
      "Batch:  134  Current RMSE:  1.2647868472850363\n",
      "Batch:  135  Current RMSE:  1.2996415473792053\n",
      "Batch:  136  Current RMSE:  1.2259425631824907\n",
      "Batch:  137  Current RMSE:  1.2544942880567207\n",
      "Batch:  138  Current RMSE:  1.2313478072306723\n",
      "Batch:  139  Current RMSE:  1.2227547173446196\n",
      "Batch:  140  Current RMSE:  1.2653327164057486\n",
      "Batch:  141  Current RMSE:  1.2506992060651771\n",
      "Batch:  142  Current RMSE:  1.2647624329227334\n",
      "Batch:  143  Current RMSE:  1.213537130978977\n",
      "Batch:  144  Current RMSE:  1.2960289357387467\n",
      "Batch:  145  Current RMSE:  1.2362007060324478\n",
      "Batch:  146  Current RMSE:  1.228575411944846\n",
      "Batch:  147  Current RMSE:  1.2204219169945874\n",
      "Batch:  148  Current RMSE:  1.2236413982085226\n",
      "Batch:  149  Current RMSE:  1.2577618139053148\n",
      "Batch:  150  Current RMSE:  1.2144543915835433\n",
      "Batch:  151  Current RMSE:  1.2410619469254445\n",
      "Batch:  152  Current RMSE:  1.1929186928724609\n",
      "Batch:  153  Current RMSE:  1.2346344105900142\n",
      "Batch:  154  Current RMSE:  1.207452643936471\n",
      "Batch:  155  Current RMSE:  1.208107660846546\n",
      "Batch:  156  Current RMSE:  1.2147820677896222\n",
      "Batch:  157  Current RMSE:  1.2846425384839604\n",
      "Batch:  158  Current RMSE:  1.2429575408281173\n",
      "Batch:  159  Current RMSE:  1.207017850495994\n",
      "Batch:  160  Current RMSE:  1.321450414547067\n",
      "Batch:  161  Current RMSE:  1.2489381642219544\n",
      "Batch:  162  Current RMSE:  1.2227106738073503\n",
      "Batch:  163  Current RMSE:  1.2722351713512332\n",
      "Batch:  164  Current RMSE:  1.3467626218410609\n",
      "Batch:  165  Current RMSE:  1.294517174455551\n",
      "Batch:  166  Current RMSE:  1.2477271614188674\n",
      "Batch:  167  Current RMSE:  1.340513713086724\n",
      "Batch:  168  Current RMSE:  1.3340755952291865\n",
      "Batch:  169  Current RMSE:  1.3025875805766032\n",
      "Batch:  170  Current RMSE:  1.2168242522867085\n",
      "Batch:  171  Current RMSE:  1.2308673231739315\n",
      "Batch:  172  Current RMSE:  1.270049077543781\n",
      "Batch:  173  Current RMSE:  1.2335461664837628\n",
      "Batch:  174  Current RMSE:  1.2844029769011467\n",
      "Batch:  175  Current RMSE:  1.2754342544950579\n",
      "Batch:  176  Current RMSE:  1.25448104336786\n",
      "Batch:  177  Current RMSE:  1.2969938039886835\n",
      "Batch:  178  Current RMSE:  1.2399318193818745\n",
      "Batch:  179  Current RMSE:  1.2931182588125636\n",
      "Batch:  180  Current RMSE:  1.2557072560196882\n",
      "Batch:  181  Current RMSE:  1.2667984927863323\n",
      "Batch:  182  Current RMSE:  1.2245648581628885\n",
      "Batch:  183  Current RMSE:  1.2344913482640711\n",
      "Batch:  184  Current RMSE:  1.200238075667411\n",
      "Batch:  185  Current RMSE:  1.1946193071358409\n",
      "Batch:  186  Current RMSE:  1.1984443929835624\n",
      "Batch:  187  Current RMSE:  1.212986738102856\n",
      "Batch:  188  Current RMSE:  1.2612218093574727\n",
      "Batch:  189  Current RMSE:  1.2280826974536416\n",
      "Batch:  190  Current RMSE:  1.2219598367265792\n",
      "Batch:  191  Current RMSE:  1.2604365292655788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  192  Current RMSE:  1.2514452821952347\n",
      "Batch:  193  Current RMSE:  1.2341033026019514\n",
      "Batch:  194  Current RMSE:  1.2625228082453057\n",
      "Batch:  195  Current RMSE:  1.279091065930939\n",
      "Batch:  196  Current RMSE:  1.2275019426283467\n",
      "Batch:  197  Current RMSE:  1.2695626543414775\n",
      "Batch:  198  Current RMSE:  1.3073490754058559\n",
      "Batch:  199  Current RMSE:  1.263462646962117\n",
      "Batch:  200  Current RMSE:  1.3063167081738878\n",
      "Batch:  201  Current RMSE:  1.3266630934707573\n",
      "Batch:  202  Current RMSE:  1.291472888030567\n",
      "Batch:  203  Current RMSE:  1.2726965485599318\n",
      "Batch:  204  Current RMSE:  1.223421584876952\n",
      "Batch:  205  Current RMSE:  1.2764813274516436\n",
      "Batch:  206  Current RMSE:  1.270893646484097\n",
      "Batch:  207  Current RMSE:  1.2312322465434002\n",
      "Batch:  208  Current RMSE:  1.240143176720261\n",
      "Batch:  209  Current RMSE:  1.2555398405753113\n",
      "Batch:  210  Current RMSE:  1.228212876020212\n",
      "Batch:  211  Current RMSE:  1.2925943984610562\n",
      "Batch:  212  Current RMSE:  1.2390615792428585\n",
      "Batch:  213  Current RMSE:  1.2234540355789807\n",
      "Batch:  214  Current RMSE:  1.235376710743666\n",
      "Batch:  215  Current RMSE:  1.2537184475532002\n",
      "Batch:  216  Current RMSE:  1.220249162521812\n",
      "Batch:  217  Current RMSE:  1.231819531326286\n",
      "Batch:  218  Current RMSE:  1.2582616785458565\n",
      "Batch:  219  Current RMSE:  1.2667808816419983\n",
      "Batch:  220  Current RMSE:  1.2195475549618515\n",
      "Batch:  221  Current RMSE:  1.2583647347674767\n",
      "Batch:  222  Current RMSE:  1.2696741040547166\n",
      "Batch:  223  Current RMSE:  1.2336498121786534\n",
      "Batch:  224  Current RMSE:  1.2547322598228106\n",
      "Batch:  225  Current RMSE:  1.3010635834099877\n",
      "Batch:  226  Current RMSE:  1.3350575102166475\n",
      "Batch:  227  Current RMSE:  1.3266557397316137\n",
      "Batch:  228  Current RMSE:  1.23996669053988\n",
      "Batch:  229  Current RMSE:  1.241300597503209\n",
      "Batch:  230  Current RMSE:  1.212118038290686\n",
      "Batch:  231  Current RMSE:  1.2822239005376732\n",
      "Batch:  232  Current RMSE:  1.1945590820887537\n",
      "Batch:  233  Current RMSE:  1.2839425029839453\n",
      "Batch:  234  Current RMSE:  1.2723733288417427\n",
      "Batch:  235  Current RMSE:  1.2068313270570552\n",
      "Batch:  236  Current RMSE:  1.2109413045083737\n",
      "Batch:  237  Current RMSE:  1.212091881345076\n",
      "Batch:  238  Current RMSE:  1.2023670117019132\n",
      "Batch:  239  Current RMSE:  1.308123683738269\n",
      "Batch:  240  Current RMSE:  1.237029423141325\n",
      "Batch:  241  Current RMSE:  1.2649031882428876\n",
      "Batch:  242  Current RMSE:  1.2193703760489005\n",
      "Batch:  243  Current RMSE:  1.289107298711714\n",
      "Batch:  244  Current RMSE:  1.2354779102652704\n",
      "Batch:  245  Current RMSE:  1.2004293014088891\n",
      "Batch:  246  Current RMSE:  1.246285070084154\n",
      "Batch:  247  Current RMSE:  1.22991915138719\n",
      "Batch:  248  Current RMSE:  1.2517700197143289\n",
      "Batch:  249  Current RMSE:  1.2671337043610582\n",
      "Batch:  250  Current RMSE:  1.2961481103699908\n",
      "Batch:  251  Current RMSE:  1.244759085645306\n",
      "Batch:  252  Current RMSE:  1.2572288872945399\n",
      "Batch:  253  Current RMSE:  1.2506351656654489\n",
      "Batch:  254  Current RMSE:  1.2115022731379663\n",
      "Batch:  255  Current RMSE:  1.2475969036848633\n",
      "Batch:  256  Current RMSE:  1.2406204211780232\n",
      "Batch:  257  Current RMSE:  1.2311429916942929\n",
      "Batch:  258  Current RMSE:  1.2198571627984147\n",
      "Batch:  259  Current RMSE:  1.294198840028393\n",
      "Batch:  260  Current RMSE:  1.2318363896600042\n",
      "Batch:  261  Current RMSE:  1.202910809363146\n",
      "Batch:  262  Current RMSE:  1.1987477640695956\n",
      "Batch:  263  Current RMSE:  1.2802721801904178\n",
      "Batch:  264  Current RMSE:  1.2539082075399761\n",
      "Batch:  265  Current RMSE:  1.2755618770187687\n",
      "Batch:  266  Current RMSE:  1.2136330521402368\n",
      "Batch:  267  Current RMSE:  1.238401734787343\n",
      "Batch:  268  Current RMSE:  1.2098866042566063\n",
      "Batch:  269  Current RMSE:  1.195358482522226\n",
      "Batch:  270  Current RMSE:  1.205379182123529\n",
      "Batch:  271  Current RMSE:  1.2775530516168598\n",
      "Batch:  272  Current RMSE:  1.3012168188632114\n",
      "Batch:  273  Current RMSE:  1.291711965476519\n",
      "Batch:  274  Current RMSE:  1.207074794518523\n",
      "Batch:  275  Current RMSE:  1.2066340906784805\n",
      "Batch:  276  Current RMSE:  1.2239705597959138\n",
      "Batch:  277  Current RMSE:  1.19421619943564\n",
      "Batch:  278  Current RMSE:  1.211388860950681\n",
      "Batch:  279  Current RMSE:  1.1975359221874418\n",
      "Batch:  280  Current RMSE:  1.2471281575283646\n",
      "Batch:  281  Current RMSE:  1.2371171823940093\n",
      "Batch:  282  Current RMSE:  1.1885739219421134\n",
      "Batch:  283  Current RMSE:  1.2580597195138434\n",
      "Batch:  284  Current RMSE:  1.255303451122127\n",
      "Batch:  285  Current RMSE:  1.2486782763382893\n",
      "Batch:  286  Current RMSE:  1.256902275351663\n",
      "Batch:  287  Current RMSE:  1.2525654936609354\n",
      "Batch:  288  Current RMSE:  1.2337415178577311\n",
      "Batch:  289  Current RMSE:  1.222268476331462\n",
      "Batch:  290  Current RMSE:  1.2574184246549573\n",
      "Batch:  291  Current RMSE:  1.2330504758726153\n",
      "Batch:  292  Current RMSE:  1.2267911132777454\n",
      "Batch:  293  Current RMSE:  1.2506160876624506\n",
      "Batch:  294  Current RMSE:  1.2639134101645708\n",
      "Batch:  295  Current RMSE:  1.2293345463471574\n",
      "Batch:  296  Current RMSE:  1.2493988964105829\n",
      "Batch:  297  Current RMSE:  1.2338081647082242\n",
      "Batch:  298  Current RMSE:  1.2176276863882243\n",
      "Batch:  299  Current RMSE:  1.228249705391758\n",
      "Batch:  300  Current RMSE:  1.2548996865302857\n",
      "Batch:  301  Current RMSE:  1.2146125371306278\n",
      "Batch:  302  Current RMSE:  1.2943340667590284\n",
      "Batch:  303  Current RMSE:  1.2054356505650559\n",
      "Batch:  304  Current RMSE:  1.2219468263425834\n",
      "Batch:  305  Current RMSE:  1.2098017498553129\n",
      "Batch:  306  Current RMSE:  1.2255202180548874\n",
      "Batch:  307  Current RMSE:  1.2248862749405447\n",
      "Batch:  308  Current RMSE:  1.252587995833665\n",
      "Batch:  309  Current RMSE:  1.326405136854753\n",
      "Batch:  310  Current RMSE:  1.2350945633288812\n",
      "Batch:  311  Current RMSE:  1.220160847886673\n",
      "Batch:  312  Current RMSE:  1.2183739122078614\n",
      "Batch:  313  Current RMSE:  1.2633484173096152\n",
      "Batch:  314  Current RMSE:  1.2392806193669188\n",
      "Batch:  315  Current RMSE:  1.2150839559271647\n",
      "Batch:  316  Current RMSE:  1.240515424865613\n",
      "Batch:  317  Current RMSE:  1.246396000722687\n",
      "Batch:  318  Current RMSE:  1.225946643416364\n",
      "Batch:  319  Current RMSE:  1.232522621108029\n",
      "Batch:  320  Current RMSE:  1.2154843326447151\n",
      "Batch:  321  Current RMSE:  1.2277332788876398\n",
      "Batch:  322  Current RMSE:  1.2160583186748553\n",
      "Batch:  323  Current RMSE:  1.2219693474102427\n",
      "Batch:  324  Current RMSE:  1.2044419275311726\n",
      "Batch:  325  Current RMSE:  1.224946370394171\n",
      "Batch:  326  Current RMSE:  1.2111120566886595\n",
      "Batch:  327  Current RMSE:  1.2255380008587322\n",
      "Batch:  328  Current RMSE:  1.2206888493755919\n",
      "Batch:  329  Current RMSE:  1.2130707350081058\n",
      "Batch:  330  Current RMSE:  0.4056007813845469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "\n",
    "def test():\n",
    "    criterion = nn.MSELoss()\n",
    "    noRatings = 0\n",
    "    input, target, minibatch = {}, {}, {}\n",
    "    \n",
    "    # True values\n",
    "    y_true = []    \n",
    "    # Predicted values\n",
    "    y_pred = []\n",
    "\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = 12, shuffle = False)\n",
    "        \n",
    "    for bidx, batch in enumerate(test_loader):\n",
    "            x_train = batch['inp']\n",
    "            y_true.append(x_train)\n",
    "            y_pred.append(model(x_train))\n",
    "            acc_rmse = 0\n",
    "            \n",
    "            for idx, tensor in enumerate (y_pred[bidx]):\n",
    "                mse = (np.square(y_true[bidx].detach().numpy() - tensor.detach().numpy())).mean(axis=None)\n",
    "                rmse = sqrt(mse) \n",
    "                acc_rmse+=rmse\n",
    "            \n",
    "            print(\"Batch: \", bidx+1, \" Current RMSE: \", acc_rmse)    \n",
    "\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-poetry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
